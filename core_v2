from PythonConfluenceAPI import ConfluenceAPI
import Configuration
import pickle
from Mechanics import PageCreator, SQLConnector, ContributionComparator, CustomLogging, ExclusionsDict, MysqlConnector
import logging
from datetime import datetime
import Page_mechanics

log_name = "Core_" + str(datetime.now().strftime("%Y-%m-%d_%H_%M_%S", )) + '.log'
#logging.basicConfig(format=u'%(filename)s[LINE:%(lineno)d]# %(levelname)-8s [%(asctime)s]  %(message)s', level=logging.INFO, filename=log_name)

def initialize(logging_mode: str = 'silent'):
    global Contrib_Compare_inst
    # Main instance, used to analyze pages and create page contribution maps based on the content,
    # collected from one of supported platforms
    global Mysql_Connector_inst
    # Here used to connect to xWIKI DB to get a list of pages from a requested space
    global ConfluenceAPI_inst
    # ConfluenceAPI_inst - same for Confluence
    global SQL_Connector_inst
    # Used to store\load page contribution maps in\from SQL
    global Page_Creator_inst
    # Creates PAGE objects - data handlers for currently analyzed page
    global Logging
    # Just Logging
    Contrib_Compare_inst = ContributionComparator()
    SQL_Config_inst = Configuration.SQLConfig()
    Confluence_Config_inst = Configuration.ConfluenceConfig()
    MediaWIKI_Config_inst = Configuration.MediaWIKIConfig()
    xWiki_Config_inst = Configuration.xWikiConfig(['Migration pool', 'Sandbox', 'Main', 'StagingWiki'])
    MySQL_Config_inst = Configuration.MySQLConfig()
    Mysql_Connector_inst = MysqlConnector(MySQL_Config_inst)
    Page_Creator_inst = PageCreator(Confluence_Config_inst, MediaWIKI_Config_inst, xWiki_Config_inst)
    SQL_Connector_inst = SQLConnector(SQL_Config_inst)
    Logging = CustomLogging(logging_mode)
    # getting all pages in Confluence:
    ConfluenceAPI_inst = ConfluenceAPI(Confluence_Config_inst.USER, Confluence_Config_inst.PASS,
                                       Confluence_Config_inst.ULR)

initialize()


# Task:
#    Confluence: VB (Veeam B&R Basic knowledge), WB (Veeam Support Hints and Tricks), GZ (Ground Zero)
#    MediaWIKI: just all
#    xWIKI: ['Blog', 'Main', 'Sandbox', 'XWiki']
Task = {
    # 'VB': 'Confluence',
    # 'WB': 'Confluence',
    # 'GZ': 'Confluence',
    # 'ALL mWIKI': 'MediaWIKI'
    # 'Main': 'xWIKI',
    # 'Sandbox': 'xWIKI',
    # 'Migration pool': 'xWIKI',
    # 'Migrated bugs': 'xWIKI'
    'Main': 'xWIKI',
    'StagingWiki': 'xWIKI'
}
TaskExclusions = ExclusionsDict()
# TaskExclusions['Confluence'] = 'List of all KBs'
# TaskExclusions['MediaWIKI'] = 'Found Bugs'
# TaskExclusions['MediaWIKI'] = 'Registry values B&R'
# TaskExclusions['MediaWIKI'] = 'Veeam ONE Registry Keys'
# TaskExclusions['MediaWIKI'] = 'Patches and fixes for B&R'
# TaskExclusions['MediaWIKI'] = 'Bug%'
# TaskExclusions['MediaWIKI'] = 'BUG%'
# TaskExclusions['MediaWIKI'] = 'bug%'
# TaskExclusions['MediaWIKI'] = 'Case Handling'
# TaskExclusions['MediaWIKI'] = 'Team Members'
TaskExclusions['xWIKI'] = None


def build_task_array(task_dict: dict, task_exclusions_dict: dict):
    global task_pages_dict, platform
    task_pages_dict = {}
    total_size = 0
    for space, platform in task_dict.items():
        if platform == 'Confluence':
            respond = ConfluenceAPI_inst.get_content('page', space, None, 'current', None, None, 0, 500)
            size = respond['size']
            total_size += size
            print(size, 'Confluence pages were found in space', space)
            try:
                confluence_pages_from_api = respond['results']
            except:
                print('Error: unable to get Confluence pages from API, aborting this space')
                continue
            for page in confluence_pages_from_api:
                if task_exclusions_dict[platform] is not None:
                    if not Page_Creator_inst.check_exclusions(page['title'], platform, task_exclusions_dict):
                        continue
                    else:
                        task_pages_dict.update({page['title']: platform})
                        size += 1
                else:
                    task_pages_dict.update({page['title']: platform})
                    size += 1
        if platform == 'MediaWIKI':
            size = 0
            for page in Page_Creator_inst.MediaWikiAPI_instance.allpages():
                if task_exclusions_dict[platform] is not None:
                    if not Page_Creator_inst.check_exclusions(page.name, platform, task_exclusions_dict):
                        # print(page.name, 'was excluded, total excluded:', Page_Creator_inst.TotalExcluded)
                        continue
                    else:
                        task_pages_dict.update({page.name: platform})
                        size += 1
                else:
                    task_pages_dict.update({page.name: platform})
                    size += 1
            print(size, 'MediaWIKI pages were found in space', space)
            total_size += size
        if platform == 'xWIKI':
            size = 0
            print('Looking for pages in the following xWIKI space:', space)
            for page in Mysql_Connector_inst.get_XWD_FULLNAMEs(space):
                if task_exclusions_dict[platform] is not None:
                    if not Page_Creator_inst.check_exclusions(page, platform, task_exclusions_dict):
                        continue
                    else:
                        task_pages_dict.update({page: platform})
                        size += 1
                else:
                    task_pages_dict.update({page: platform})
                    size += 1
            print(size, 'xWIKI pages were found in space', space)
            total_size += size
    Logging.log_task_start(total_size, Page_Creator_inst.TotalExcluded)
    return task_pages_dict

task_pages_dict = build_task_array(task_dict=Task, task_exclusions_dict=TaskExclusions)

for title, platform in task_pages_dict.items():
    if platform == 'xWIKI':
        currently_analyzed_page = Page_mechanics.PageXWiki(page_title=Mysql_Connector_inst.get_XWD_TITLE(title), page=title)
        print(currently_analyzed_page.path)
